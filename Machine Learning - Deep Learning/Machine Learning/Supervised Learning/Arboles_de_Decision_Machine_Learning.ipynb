{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 游쮫릛 **츼rboles de Decisi칩n en Machine Learning** 游쓇릱"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los 츼rboles de Decisi칩n son un tipo de modelo de aprendizaje autom치tico que se utilizan tanto para resolver problemas de clasificaci칩n como de regresi칩n. Estos modelos se basan en la idea de tomar decisiones basadas en caracter칤sticas, como se har칤a en un proceso de toma de decisiones humano.\n",
    "\n",
    "\n",
    "Un 츼rbol de Decisi칩n se compone de nodos y hojas.\n",
    "\n",
    "    a) 쯈ue es un nodo?: Cada nodo representa una decisi칩n basada en una caracter칤stica.\n",
    "    b) 쯈uue es una hoja?: Cada hoja representa una clase o un valor predictivo. \n",
    "\n",
    "El proceso de crear un 츼rbol de Decisi칩n consiste en elegir las caracter칤sticas m치s relevantes y utilizarlas para dividir el conjunto de datos en subconjuntos m치s peque침os. Este proceso se repite hasta que se cumpla una condici칩n de detenci칩n, como el n칰mero m치ximo de niveles o el tama침o m칤nimo de un subconjunto.\n",
    "\n",
    "\n",
    "Los 츼rboles de Decisi칩n son f치ciles de entender y visualizar, lo que los hace muy 칰tiles para el an치lisis exploratorio de datos. Sin embargo, tambi칠n pueden ser propensos a sobreajustarse a los datos de entrenamiento si no se limita su crecimiento adecuadamente. Por lo tanto, es importante utilizar t칠cnicas de poda y validaci칩n cruzada para evitar este problema.\n",
    "\n",
    "\n",
    "Tenemos dos tipos de 치rboles de decisi칩n:\n",
    "\n",
    "- 츼rboles de Clasificaci칩n.\n",
    "- 츼rboles de Regresi칩n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游볞 **츼rboles de Clasificaci칩n** 游볞"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 쯈u칠 es un 츼rbol de Clasificaci칩n?\n",
    "\n",
    "        Es un modelo de aprendizaje autom치tico que se utiliza para resolver problemas de clasificaci칩n. Cada nodo representa una decisi칩n y cada hoja representa una clase.\n",
    "\n",
    "2) 쮺칩mo funciona?\n",
    "\n",
    "        Se empieza desde la ra칤z y se toma una decisi칩n en cada nodo basada en una caracter칤stica. Se sigue el camino hasta llegar a una hoja y la clase en la hoja se asigna como la clase de la instancia.\n",
    "\n",
    "3) 쮺칩mo se crea un 츼rbol de Clasificaci칩n?\n",
    "\n",
    "        Se eligen las caracter칤sticas m치s relevantes y se utilizan para dividir el conjunto de datos en subconjuntos m치s peque침os. Se repite este proceso hasta que se cumpla una condici칩n de detenci칩n, como el n칰mero m치ximo de niveles o el tama침o m칤nimo de un subconjunto.\n",
    "\n",
    "4) 쮺u치les son las m칠tricas utilizadas para evaluar un 츼rbol de Clasificaci칩n?\n",
    "\n",
    "        Exactitud: porcentaje de instancias clasificadas correctamente.\n",
    "        \n",
    "        Matriz de Confusi칩n: muestra el n칰mero de falsos positivos, falsos negativos, verdaderos positivos y verdaderos negativos.\n",
    "\n",
    "        Curva ROC: muestra la relaci칩n entre la tasa de verdaderos positivos y la tasa de falsos positivos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un modelo simple de un 치rbol de clasificaci칩n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos en un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"archivo.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en caracter칤sticas y etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en conjuntos de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto de 츼rbol de Clasificaci칩n (Con max_depth \"podamos\" el 치rbol para que tenga una profundidad m치xima de 3 [2 o 3 es lo normal]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos de X_train e y_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la predicci칩n con X_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la exactitud del modelo (utlizaremos el accuracy, pero es la peor, se pueden utilizar otras) y la saco por pantalla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Exactitud: \", acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el 츼rbol de Clasificaci칩n con un plot:\n",
    "\n",
    "    Determinamos el tama침o de la figura con el figsize.\n",
    "    Sacamos el arbol con el plot_tree indicando el modelo: 'clf', 'filled=True' para los colores de los nodos y 'fontsize' para etiquetar los nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, filled=True, fontsize=10);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, la creaci칩n de un modelo de 츼rbol de Clasificaci칩n implica la selecci칩n de caracter칤sticas relevantes, la divisi칩n del conjunto de datos en subconjuntos, la asignaci칩n de clases a las hojas y la evaluaci칩n del modelo. Cada paso es importante para garantizar un rendimiento preciso y efectivo del modelo. Adem치s, es importante tener en cuenta la posibilidad de overfitting y utilizar t칠cnicas de poda y validaci칩n cruzada para prevenirlo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游늳 **츼rboles de Regresi칩n** 游늳"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 쯈u칠 es un 츼rbol de Regresi칩n?\n",
    "\n",
    "        Es un modelo de aprendizaje autom치tico que se utiliza para resolver problemas de regresi칩n. Cada hoja representa un valor predictivo.\n",
    "\n",
    "2) 쮺칩mo funciona?\n",
    "\n",
    "        Se empieza desde la ra칤z y se toma una decisi칩n en cada nodo basada en una caracter칤stica. Se sigue el camino hasta llegar a una hoja y el valor en la hoja se asigna como la predicci칩n para la instancia.\n",
    "\n",
    "3) 쮺칩mo se crea un 츼rbol de Regresi칩n?\n",
    "\n",
    "        Se eligen las caracter칤sticas m치s relevantes y se utilizan para dividir el conjunto de datos en subconjuntos m치s peque침os. Se repite este proceso hasta que se cumpla una condici칩n de detenci칩n, como el n칰mero m치ximo de niveles o el tama침o m칤nimo de un subconjunto. Para cada subconjunto, se calcula el valor predictivo medio y se asigna a la hoja correspondiente.\n",
    "\n",
    "4) 쮺u치les son las m칠tricas utilizadas para evaluar un 츼rbol de Regresi칩n?\n",
    "\n",
    "        Error cuadr치tico medio (MSE, por sus siglas en ingl칠s): Es la media de los cuadrados de las diferencias entre los valores reales y los valores predecidos. Un MSE bajo indica un buen ajuste del modelo.\n",
    "\n",
    "        Ra칤z del error cuadr치tico medio (RMSE, por sus siglas en ingl칠s): Es la ra칤z cuadrada del MSE. Al igual que el MSE, un RMSE bajo indica un buen ajuste del modelo.\n",
    "\n",
    "        Coeficiente de determinaci칩n (R^2): Es una medida de cu치n bien se ajusta el modelo a los datos. Un valor de R^2 cercano a 1 indica un ajuste excelente, mientras que un valor cercano a 0 indica un ajuste pobre.\n",
    "\n",
    "        Error absoluto medio (MAE, por sus siglas en ingl칠s): Es la media de las diferencias absolutas entre los valores reales y los valores predecidos. Al igual que el MSE y el RMSE, un MAE bajo indica un buen ajuste del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un modelo simple de un 치rbol de regresi칩n (Este le haremos con poda y haremos tambien un GridSearchCV para optimizar):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos en un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"archivo.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en caracter칤sticas y etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir los datos en conjuntos de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto de 츼rbol de Regresi칩n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los par치metros que probaremos en la b칰squeda en malla para optimizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [2, 3, 4, 5, 6],\n",
    "              'min_samples_split': [2, 3, 4, 5]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto de GridSearchCV con el modelo, los par치metros definidos anteriormente y el n칰mero de K-folds con cv (ser치n 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(regr, param_grid, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos de X-train e y_train y realizamos la b칰squeda en malla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la prediccion con los datos de X-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el error cuadr치tico medio (MSE) y lo sacamos por pantalla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Error cuadr치tico medio: \", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos por pantalla los mejores par치metros encontrados en la b칰squeda en malla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores par치metros: \", grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el mejor modelo de la b칰squeda en malla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr = grid_search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el 츼rbol de Regresi칩n:\n",
    "\n",
    "    Sacamos el arbol con el plot_tree indicando el modelo (en este caso el que nos salga como mejor seg칰n el CV): 'best_regr', 'filled=True' para los colores de los nodos y 'fontsize' para etiquetar los nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(best_regr, filled=True, fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, la creaci칩n de un 츼rbol de Regresi칩n implica la selecci칩n de caracter칤sticas relevantes, la divisi칩n del conjunto de datos en subconjuntos y la asignaci칩n de un valor predictivo medio a cada hoja. La condici칩n de detenci칩n se utiliza para controlar la complejidad del modelo y evitar el overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
