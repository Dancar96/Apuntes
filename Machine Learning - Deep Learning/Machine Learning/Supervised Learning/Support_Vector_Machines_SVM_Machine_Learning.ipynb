{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **M谩quinas de Vector Soporte o Support Vector Machines (SVM)** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 驴Qu茅 son los Support Vector Machines (SVM)? \n",
    "\n",
    "SVM es un algoritmo de aprendizaje supervisado utilizado para la clasificaci贸n y la regresi贸n. Un SVM encuentra un hiperplano en un espacio de alta dimensi贸n que separa los datos en clases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴C贸mo funciona un SVM? \n",
    "\n",
    "SVM encuentra el hiperplano que maximiza el margen entre las dos clases. El margen es la distancia entre el hiperplano y los puntos de datos m谩s cercanos de cada clase. Los puntos de datos m谩s cercanos a cada clase son llamados vectores de soporte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴Cu谩l es el proceso de entrenamiento de un SVM? 锔\n",
    "\n",
    "Seleccionar un kernel (lineal, polinomial, RBF, etc.) para transformar los datos de entrada.\n",
    "Encontrar el hiperplano que maximiza el margen utilizando un algoritmo de optimizaci贸n (como el algoritmo SMO).\n",
    "Entrenar el modelo en los datos de entrenamiento y ajustar los par谩metros."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴C贸mo se realiza la clasificaci贸n con un SVM? \n",
    "\n",
    "Un nuevo punto de datos se transforma con el mismo kernel que se utiliz贸 durante el entrenamiento.\n",
    "Se clasifica el punto de datos en una de las dos clases seg煤n el lado del hiperplano en el que cae."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴Qu茅 son los par谩metros de un SVM? 锔\n",
    "\n",
    "- C: par谩metro de regularizaci贸n que controla el error de clasificaci贸n en el conjunto de entrenamiento.\n",
    "- Kernel: funci贸n utilizada para transformar los datos de entrada en un espacio de mayor dimensi贸n.\n",
    "- Gamma: par谩metro del kernel utilizado para controlar la flexibilidad del modelo.\n",
    "- Epsilon: margen de error permitido para el ajuste de los vectores de soporte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴Qu茅 son las ventajas y desventajas de un SVM? \n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Efectivo con muchas features: Los SVM son muy efectivos en problemas con un gran n煤mero de caracter铆sticas o features, incluso cuando la cantidad de caracter铆sticas es mayor que el n煤mero de muestras.\n",
    "    - Eficaz computacionalmente: A pesar de que los SVM son muy precisos, son muy eficientes en t茅rminos de c贸mputo, lo que los hace ideales para grandes conjuntos de datos.\n",
    "    - Varios kernels para varios problemas: Los SVM tienen una variedad de kernels para abordar una variedad de problemas, incluyendo lineal, polinomial, RBF, sigmoid, entre otros.\n",
    "    - Clasificaci贸n/Regresi贸n: Los SVM pueden ser utilizados tanto para clasificaci贸n como para regresi贸n.\n",
    "    - Robustos frente overfitting: Los SVM tienen una gran capacidad para evitar el sobreajuste o overfitting de los datos de entrenamiento.\n",
    "    - Robustos frente outliers: Los SVM son resistentes a los datos at铆picos o outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desventajas:\n",
    "\n",
    "    - Mal performance si el n煤mero de features es mayor que el n煤mero de muestras: Los SVM pueden tener un rendimiento pobre cuando la cantidad de caracter铆sticas es mucho mayor que la cantidad de muestras.\n",
    "    - Hay que realizar mucha combinatoria de kernels e hiperpar谩metros para conseguir el modelo 贸ptimo: En la b煤squeda de un buen modelo SVM, puede ser necesario realizar una gran cantidad de experimentaci贸n con diferentes combinaciones de kernels y par谩metros, lo que puede ser muy costoso en t茅rminos de tiempo y recursos.\n",
    "    - Es caja negra: La interpretaci贸n de un modelo SVM puede ser dif铆cil debido a su complejidad y su naturaleza de caja negra, lo que significa que no es f谩cil entender c贸mo se ha llegado a una determinada predicci贸n o clasificaci贸n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴Qu茅 tipos de SVM hay? 碉\n",
    "\n",
    "Hay dos tipos de SVM, los lineales y los no lineales.\n",
    "\n",
    "1) SVM lineal: En un SVM lineal, los datos se separan mediante un hiperplano que es una l铆nea recta en un espacio de dos dimensiones, un plano en un espacio de tres dimensiones o un hiperplano en un espacio de m谩s de tres dimensiones. Esto significa que la separaci贸n entre las clases se realiza mediante una funci贸n lineal.\n",
    "\n",
    "2) SVM no lineal: En un SVM no lineal se utiliza una funci贸n de kernel para transformar los datos en un espacio de alta dimensi贸n donde se pueden separar mediante un hiperplano no lineal. La funci贸n de kernel es una funci贸n que mide la similitud entre dos vectores en un espacio de alta dimensi贸n. Al aplicar una funci贸n de kernel, se puede realizar una transformaci贸n no lineal de los datos originales para que puedan ser separados por un hiperplano en ese espacio de alta dimensi贸n. Es decir, si la muestra esta en dimensi贸n n, mediante el 'kernel trick' se transforma esa dimensi贸n n a una dimensi贸n n+1, as铆 ser谩 m谩s facil crear un hiperplano que separe los datos.\n",
    "\n",
    "En resumen, la principal diferencia entre un SVM lineal y un SVM no lineal es que el primero utiliza una funci贸n lineal para separar los datos, mientras que el segundo utiliza una funci贸n de kernel para transformar los datos y encontrar un hiperplano de separaci贸n no lineal en un espacio de alta dimensi贸n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a ver un ejemplo sencillo de SVM lineal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesrias (vamos a utilizar la m茅trica de F-1 Score para evaluar el rendiiento del modelo y vamos a crerar un Pipeline para encadenar los pasos de Preprocesado y Modelado en un solo objeto Pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos del archivo csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frutas = pd.read_csv('datos_frutas.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto Pipeline donde agruparemos el preprocesado, en este caso la estandarizaci贸n, y el modelado, un SVM lineal en un solo paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos del conjunto en X e Y y creamos los conjuntos de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frutas[['peso', 'tama帽o']]\n",
    "y = frutas['clase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos al modelo con X_train e y_train mediante el Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el F1-Score para evaluar el rendimiento del modelo SVM lineal y lo printeamos por pantalla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score del modelo: {:.2f}\".format(f1score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos usando el pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_fruta = [[150, 2]]\n",
    "prediccion = pipe.predict(nueva_fruta)\n",
    "print(\"La fruta es una:\", prediccion[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos a ver el mismo ejemplo pero empleando un SVM no lineal, en el que tendremos que expecificar el Kernel trick que queremos emplear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias (aqu铆 tambien utilizaremos la F1-Score y el Pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de un csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frutas = pd.read_csv('datos_frutas.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto Pipeline donde agruparemos el preprocesado, en este caso la estandarizaci贸n, y el modelado, un SVM lineal en un solo paso:\n",
    "- El kernel por defecto es el especificado aqu铆, 'rbf' (radial basis function o funci贸n de base radial), pero podemos utilizar 'poly' para polinomicas, 'sigmoid' para regresiones logisticas, o 'precomputed'para utilizar una matriz de gram precomputada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(kernel='rbf', gamma='scale'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos del conjunto en X e Y y creamos los conjuntos de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frutas[['peso', 'tama帽o']]\n",
    "y = frutas['clase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos al modelo con X_train e y_train mediante el Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el F1-Score para evaluar el rendimiento del modelo SVM lineal y lo printeamos por pantalla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score del modelo: {:.2f}\".format(f1score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos usando el pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_fruta = [[150, 2]]\n",
    "prediccion = pipe.predict(nueva_fruta)\n",
    "print(\"La fruta es una:\", prediccion[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
