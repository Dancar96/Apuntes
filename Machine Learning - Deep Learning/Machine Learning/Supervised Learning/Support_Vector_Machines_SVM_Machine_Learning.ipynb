{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦾 **Máquinas de Vector Soporte o Support Vector Machines (SVM)** 🦾"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué son los Support Vector Machines (SVM)? 🤔\n",
    "\n",
    "SVM es un algoritmo de aprendizaje supervisado utilizado para la clasificación y la regresión. Un SVM encuentra un hiperplano en un espacio de alta dimensión que separa los datos en clases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona un SVM? 🤖\n",
    "\n",
    "SVM encuentra el hiperplano que maximiza el margen entre las dos clases. El margen es la distancia entre el hiperplano y los puntos de datos más cercanos de cada clase. Los puntos de datos más cercanos a cada clase son llamados vectores de soporte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuál es el proceso de entrenamiento de un SVM? 🏋️\n",
    "\n",
    "Seleccionar un kernel (lineal, polinomial, RBF, etc.) para transformar los datos de entrada.\n",
    "Encontrar el hiperplano que maximiza el margen utilizando un algoritmo de optimización (como el algoritmo SMO).\n",
    "Entrenar el modelo en los datos de entrenamiento y ajustar los parámetros."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se realiza la clasificación con un SVM? 🏆\n",
    "\n",
    "Un nuevo punto de datos se transforma con el mismo kernel que se utilizó durante el entrenamiento.\n",
    "Se clasifica el punto de datos en una de las dos clases según el lado del hiperplano en el que cae."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué son los parámetros de un SVM? 🗃️\n",
    "\n",
    "- C: parámetro de regularización que controla el error de clasificación en el conjunto de entrenamiento.\n",
    "- Kernel: función utilizada para transformar los datos de entrada en un espacio de mayor dimensión.\n",
    "- Gamma: parámetro del kernel utilizado para controlar la flexibilidad del modelo.\n",
    "- Epsilon: margen de error permitido para el ajuste de los vectores de soporte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué son las ventajas y desventajas de un SVM? 📈📉\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Efectivo con muchas features: Los SVM son muy efectivos en problemas con un gran número de características o features, incluso cuando la cantidad de características es mayor que el número de muestras.\n",
    "    - Eficaz computacionalmente: A pesar de que los SVM son muy precisos, son muy eficientes en términos de cómputo, lo que los hace ideales para grandes conjuntos de datos.\n",
    "    - Varios kernels para varios problemas: Los SVM tienen una variedad de kernels para abordar una variedad de problemas, incluyendo lineal, polinomial, RBF, sigmoid, entre otros.\n",
    "    - Clasificación/Regresión: Los SVM pueden ser utilizados tanto para clasificación como para regresión.\n",
    "    - Robustos frente overfitting: Los SVM tienen una gran capacidad para evitar el sobreajuste o overfitting de los datos de entrenamiento.\n",
    "    - Robustos frente outliers: Los SVM son resistentes a los datos atípicos o outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desventajas:\n",
    "\n",
    "    - Mal performance si el número de features es mayor que el número de muestras: Los SVM pueden tener un rendimiento pobre cuando la cantidad de características es mucho mayor que la cantidad de muestras.\n",
    "    - Hay que realizar mucha combinatoria de kernels e hiperparámetros para conseguir el modelo óptimo: En la búsqueda de un buen modelo SVM, puede ser necesario realizar una gran cantidad de experimentación con diferentes combinaciones de kernels y parámetros, lo que puede ser muy costoso en términos de tiempo y recursos.\n",
    "    - Es caja negra: La interpretación de un modelo SVM puede ser difícil debido a su complejidad y su naturaleza de caja negra, lo que significa que no es fácil entender cómo se ha llegado a una determinada predicción o clasificación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué tipos de SVM hay? 🕵️\n",
    "\n",
    "Hay dos tipos de SVM, los lineales y los no lineales.\n",
    "\n",
    "1) SVM lineal: En un SVM lineal, los datos se separan mediante un hiperplano que es una línea recta en un espacio de dos dimensiones, un plano en un espacio de tres dimensiones o un hiperplano en un espacio de más de tres dimensiones. Esto significa que la separación entre las clases se realiza mediante una función lineal.\n",
    "\n",
    "2) SVM no lineal: En un SVM no lineal se utiliza una función de kernel para transformar los datos en un espacio de alta dimensión donde se pueden separar mediante un hiperplano no lineal. La función de kernel es una función que mide la similitud entre dos vectores en un espacio de alta dimensión. Al aplicar una función de kernel, se puede realizar una transformación no lineal de los datos originales para que puedan ser separados por un hiperplano en ese espacio de alta dimensión. Es decir, si la muestra esta en dimensión n, mediante el 'kernel trick' se transforma esa dimensión n a una dimensión n+1, así será más facil crear un hiperplano que separe los datos.\n",
    "\n",
    "En resumen, la principal diferencia entre un SVM lineal y un SVM no lineal es que el primero utiliza una función lineal para separar los datos, mientras que el segundo utiliza una función de kernel para transformar los datos y encontrar un hiperplano de separación no lineal en un espacio de alta dimensión."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a ver un ejemplo sencillo de SVM lineal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesrias (vamos a utilizar la métrica de F-1 Score para evaluar el rendiiento del modelo y vamos a crerar un Pipeline para encadenar los pasos de Preprocesado y Modelado en un solo objeto Pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos del archivo csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frutas = pd.read_csv('datos_frutas.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto Pipeline donde agruparemos el preprocesado, en este caso la estandarización, y el modelado, un SVM lineal en un solo paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos del conjunto en X e Y y creamos los conjuntos de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frutas[['peso', 'tamaño']]\n",
    "y = frutas['clase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos al modelo con X_train e y_train mediante el Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el F1-Score para evaluar el rendimiento del modelo SVM lineal y lo printeamos por pantalla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score del modelo: {:.2f}\".format(f1score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos usando el pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_fruta = [[150, 2]]\n",
    "prediccion = pipe.predict(nueva_fruta)\n",
    "print(\"La fruta es una:\", prediccion[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos a ver el mismo ejemplo pero empleando un SVM no lineal, en el que tendremos que expecificar el Kernel trick que queremos emplear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias (aquí tambien utilizaremos la F1-Score y el Pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de un csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frutas = pd.read_csv('datos_frutas.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto Pipeline donde agruparemos el preprocesado, en este caso la estandarización, y el modelado, un SVM lineal en un solo paso:\n",
    "- El kernel por defecto es el especificado aquí, 'rbf' (radial basis function o función de base radial), pero podemos utilizar 'poly' para polinomicas, 'sigmoid' para regresiones logisticas, o 'precomputed'para utilizar una matriz de gram precomputada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(kernel='rbf', gamma='scale'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos del conjunto en X e Y y creamos los conjuntos de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frutas[['peso', 'tamaño']]\n",
    "y = frutas['clase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos al modelo con X_train e y_train mediante el Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el F1-Score para evaluar el rendimiento del modelo SVM lineal y lo printeamos por pantalla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score del modelo: {:.2f}\".format(f1score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos usando el pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_fruta = [[150, 2]]\n",
    "prediccion = pipe.predict(nueva_fruta)\n",
    "print(\"La fruta es una:\", prediccion[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
